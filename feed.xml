<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://fahimhafiz.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fahimhafiz.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-10T14:26:27+00:00</updated><id>https://fahimhafiz.github.io/feed.xml</id><title type="html">blank</title><subtitle>Interested in computer vision, AI, bioinformatics and HCI. </subtitle><entry><title type="html">Paper on spatial transcriptomics imputation published in Briefings in Bioinformatics!</title><link href="https://fahimhafiz.github.io/blog/2026/SpaMeanImpute/" rel="alternate" type="text/html" title="Paper on spatial transcriptomics imputation published in Briefings in Bioinformatics!"/><published>2026-02-02T00:01:13+00:00</published><updated>2026-02-02T00:01:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2026/SpaMeanImpute</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2026/SpaMeanImpute/"><![CDATA[<h2 id="thrilled-to-announce-my-latest-publication-in-briefings-in-bioinformatics">Thrilled to announce my latest publication in <em>Briefings in Bioinformatics</em>!</h2> <p>Our study, <strong>Spatial information matters: are traditional imputation methods effective for spatial transcriptomics data?</strong>, explores the critical role of spatial context in improving imputation for high-resolution spatially resolved transcriptomics (SRT).</p> <h3 id="-why-this-matters">üîç Why this matters</h3> <p>SRT technologies provide near single-cell resolution, unlocking unprecedented biological insights. Yet, these datasets are often sparse and plagued by <strong>dropout events</strong>, making accurate interpretation challenging. Traditional imputation methods fall short when applied to emerging SRT platforms.</p> <h3 id="-what-we-built">üí° What we built</h3> <p>We benchmarked <strong>seven state-of-the-art imputation methods</strong> across <strong>five SRT platforms</strong> and <strong>23 datasets</strong>. Our findings revealed that no single method consistently excels‚Äîhighlighting the need for spatially aware approaches.</p> <p>To address this, we developed <strong>SpaMean-Impute</strong>, a novel imputation method that integrates spatial information to better recover missing values and detect valid dropouts.</p> <h3 id="-key-results">üß™ Key Results</h3> <ul> <li>üìà <strong>Performance gains over SOTA methods</strong>: <ul> <li><strong>+16.15% ARI</strong></li> <li><strong>+18.45% NMI</strong></li> <li><strong>+18.96% AMI</strong></li> <li><strong>+13.98% HOMO</strong></li> </ul> </li> <li>‚ö° <strong>Efficiency boost</strong>: ~33√ó faster and ~1500 MB less memory usage compared to deep learning-based imputation methods.</li> </ul> <h3 id="-impact">üåê Impact</h3> <p>SpaMean-Impute demonstrates how leveraging spatial context can significantly improve both accuracy and efficiency in SRT data analysis‚Äîpaving the way for more reliable biological discoveries.</p> <p>Grateful to my co-authors <strong>Riasat Azim</strong> and <strong>Swakkhar Shatabda</strong> for their collaboration and insights. Excited to see how this work contributes to advancing computational biology!</p> <p>Check out the full paper and source code here:<br/> Paper Link: <a href="https://doi.org/10.1093/bib/bbag027">https://doi.org/10.1093/bib/bbag027</a></p> <p>Source Code: <a href="https://github.com/FahimHafiz/SpaMean-Impute">https://github.com/FahimHafiz/SpaMean-Impute</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paper on spatial transcriptomics imputation published in Briefings in Bioinformatics!]]></summary></entry><entry><title type="html">Defended my master‚Äôs in CSE thesis on Spatial Transcriptomics!</title><link href="https://fahimhafiz.github.io/blog/2025/MS-defense/" rel="alternate" type="text/html" title="Defended my master‚Äôs in CSE thesis on Spatial Transcriptomics!"/><published>2025-10-20T00:01:13+00:00</published><updated>2025-10-20T00:01:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/MS%20defense</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/MS-defense/"><![CDATA[<h2 id="finally-i-defened-my-masters-thesis-on-spatial-transcrtiptomics">Finally, I defened my master‚Äôs thesis on Spatial Transcrtiptomics!</h2> <p>New technologies in Spatially Resolved Transcriptomics (SRT) Data have achieved near single-cell resolution while consisting of spatial data that has an immense impact in discovering various biological insights. High-resolution SRT data are sparse and con- tain dropouts, which may hinder the accurate interpretation of spatial domains. Hence, computationally available imputation methods are often necessary to impute the dropouts from such datasets. Numerous state-of-the-art (SOTA) imputation methods already ex- ist that are used in general tabular data, dedicated single-cell RNA data, as well as the SRT datasets. However, there is no benchmarking of these imputation methods on these newer SRT technologies‚Äô datasets. In this work, we select seven SOTA imputation meth- ods and provide detailed benchmarking results on five SRT technologies consisting of 23 datasets. We show that there are no single imputation methods that consistently out- perform others, demonstrating poor imputation capability in most cases, and also poor performance in identifying valid dropouts. Thus, analyzing these SOTA methods‚Äô per- formance, we propose a new imputation method, <strong>‚ÄòSpaMean-Impute‚Äô</strong>, designed for SRT datasets that utilize spatial information while mitigating dropouts. Furthermore, the pro- posed method can detect valid dropouts, unlike the SOTA benchmarked methods. Due to integration of spatial information-based dropout location detection, ‚ÄòSpaMean-Impute‚Äô only imputes a valid location while preserving the inherent biological relations of the datasets, unlike SOTA methods. Our proposed method outperforms the SOTA impu- tation methods across evaluation metrics such as: Adjusted Rand Index(ARI), Normal- ized Mutual Information (NMI), Adjusted Mutual Information(AMI), and Homogeneity (HOMO). In case of ARI, the proposed method outperforms the SOTA methods on av- erage 16.15%, whereas 18.45% improvement in NMI, 18.96% improvement in AMI, and 13.98% improvement in the case of HOMO. Furthermore, the proposed method is com- putationally efficient compared to other SOTA methods. For example, compared to the SOTA deep-learning-based imputation methods, the proposed method is approximately 33 times faster and requires, on average, 1500 MB less memory during imputation.</p> <p>Full Presentation Link:</p> <p><a href="https://drive.google.com/file/d/1bPS52Br1yaV9hDxIQxJx5qyiE8VTwx__/view?usp=sharing">Fahim‚Äôs Master‚Äôs presentation</a></p> <p>Source Code:</p> <p><a href="https://github.com/FahimHafiz/SpaMean-Impute">https://github.com/FahimHafiz/SpaMean-Impute</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Defended my master's in CSE thesis on Spatial Transcriptomics!]]></summary></entry><entry><title type="html">Paper on intepretable and privacy preserved lung cancer detection published in Biomedical Signal Processing and Control!</title><link href="https://fahimhafiz.github.io/blog/2025/FVCMNet/" rel="alternate" type="text/html" title="Paper on intepretable and privacy preserved lung cancer detection published in Biomedical Signal Processing and Control!"/><published>2025-10-02T00:01:13+00:00</published><updated>2025-10-02T00:01:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/FVCMNet</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/FVCMNet/"><![CDATA[<h2 id="excited-to-share-our-latest-research-published-in-biomedical-signal-processing-and-control">Excited to share our latest research published in <em>Biomedical Signal Processing and Control</em>!</h2> <p>We introduced <strong>FVCM-Net</strong>, a novel deep learning framework designed to tackle one of the most pressing challenges in healthcare: <strong>early and accurate detection of lung cancer</strong>.</p> <h3 id="-why-this-matters">üîç Why this matters</h3> <p>Lung cancer remains a leading cause of cancer-related deaths worldwide. Early detection is critical‚Äîbut building robust, generalizable models is difficult due to <strong>privacy concerns</strong> and <strong>data scarcity</strong> across institutions.</p> <h3 id="-what-we-built">üí° What we built</h3> <p>FVCM-Net combines the strengths of:</p> <ul> <li>‚úÖ <strong>VGG16 + CBAM</strong> for attention-guided, explainable lung cancer detection</li> <li>üîê <strong>Federated Learning</strong> to preserve patient privacy while enabling collaborative model training across institutions</li> <li>üß† <strong>Ensemble Learning</strong> to boost predictive accuracy and robustness</li> </ul> <h3 id="-key-results">üß™ Key Results</h3> <ul> <li>üìà Federated + Ensemble learning: <strong>97.37% accuracy</strong>, <strong>97.37% F1-score</strong></li> <li>üèÜ Ensemble learning alone: <strong>98.26% accuracy</strong>, enhancing clinical decision support</li> </ul> <h3 id="-interpretability-matters">üß¨ Interpretability matters</h3> <p>We integrated <strong>XAI techniques</strong> like <strong>SHAP</strong> and <strong>HiResCAM</strong> to visualize and explain model decisions‚Äîempowering radiologists with transparent AI support.</p> <h3 id="-datasets-used">üìö Datasets used</h3> <p>Our model was trained and validated on diverse lung CT scan datasets:</p> <ul> <li>LIDC-IDRI</li> <li>IQ-OTH/NCCD</li> <li>Kaggle public dataset</li> <li>Additional online sources</li> </ul> <h3 id="-impact">üåê Impact</h3> <p>FVCM-Net demonstrates how privacy-preserving, explainable AI can revolutionize medical imaging‚Äîsupporting clinicians with accurate, interpretable insights. Grateful to my co-authors, mentors, and collaborators who made this possible. Let‚Äôs keep pushing the boundaries of AI in healthcare! Check out the full paper and source code here: Paper Link: <a href="https://www.sciencedirect.com/science/article/pii/S1746809425012303?dgcid=coauthor">https://www.sciencedirect.com/science/article/pii/S1746809425012303?dgcid=coauthor</a></p> <p>Source Code:</p> <p><a href="https://github.com/Duranta19/BioInfo-LuC-Federated/">https://github.com/Duranta19/BioInfo-LuC-Federated/</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paper on intepretable and privacy preserved lung cancer detection published in Biomedical Signal Processing and Control!]]></summary></entry><entry><title type="html">My Experience as the co-mentor of UIU MARINER and participating in MATEROV World Championship-2025 at USA</title><link href="https://fahimhafiz.github.io/blog/2025/MATEROV/" rel="alternate" type="text/html" title="My Experience as the co-mentor of UIU MARINER and participating in MATEROV World Championship-2025 at USA"/><published>2025-08-22T00:12:13+00:00</published><updated>2025-08-22T00:12:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/MATEROV</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/MATEROV/"><![CDATA[<h1 id="-uiu-mariner-makes-history-at-mate-rov-world-championship-2025">üåä UIU MARINER Makes History at MATE ROV World Championship 2025</h1> <p>We are thrilled to announce that <em>UIU MARINER, the underwater robotics team from United International University (UIU), has ranked <strong>5th globally</strong> in the *Pioneer category</em> at the prestigious <em>2025 MATE ROV World Championship</em> held in the USA. This marks a historic moment as <em>the first-ever Bangladeshi team</em> to participate and win in this elite international competition.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/MARINER_1.jpeg?raw=true" alt="Figure 1. Team UIU MARINER at the competition venue" width="900"/> <br/></p> <figcaption style="text-align: center;">Figure 1. Team UIU MARINER at the competition venue</figcaption> <p>Not only did we secure a top-five global position, but we also clinched the <em>Best Technical Documentation Award</em>, a testament to our commitment to precision, clarity, and engineering excellence.</p> <blockquote> <p>‚ÄúWe, UIU MARINER, became 5th worldwide in the Pioneer category at the 2025 MATE ROV World Championship. We have also won the Best Technical Documentation segment! This is the first time a team from Bangladesh has participated and won at this prestigious underwater robotics competition.‚Äù</p> </blockquote> <hr/> <h2 id="my-experience">My Experience</h2> <p>As a lecturer in Computer Science and Engineering at UIU, I had the honor of accompanying the team to the United States. The competition was held in Great Lakes Maritime Heritage Center in Alpena, Michigan. We traveled for around 40 hours to reach Chiacgo and then stayed at a motel there. Afterwards, we traveled by road to reach rogers city, Michigan near Alpena. The journey was more than geographical‚Äîit was a leap into global innovation, collaboration, and representation.</p> <p>From visa preparations to navigating international logistics, every step was a learning curve. I witnessed firsthand the resilience and brilliance of our students as they competed with teams from across the globe, showcasing Bangladeshi talent on an international stage.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/MARINER_2.jpeg?raw=true" alt="Figure 2. After Safety Inspection of our ROV (P:S: We passed the safety check with flying colors!)" width="900"/> <br/></p> <figcaption style="text-align: center;">Figure 2. After Safety Inspection of our ROV (P:S: We passed the safety check with flying colors!)</figcaption> <p>My contributions spanned multiple dimensions:</p> <ul> <li><em>Technical Guidance</em>: I supported the team in the electrical segment, helping refine circuitry.</li> <li><em>Logistics &amp; Management</em>: Coordinated travel, documentation, and on-site arrangements to ensure smooth participation.</li> <li><em>Documentation Excellence</em>: Assisted in technical report, emphasizing reproducibility, clarity, and innovation.</li> </ul> <p>After the competition, we visited University of Chicago! The university‚Äôs surrounding environment was inspiring. I, along with my students were amazed at the facilities they have. We hope that such our university back home will someday follow footsteps of top universities like University of Chiacgo.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/MARINER_3.jpeg?raw=true" alt="Figure 3. Visiting University of Chicago!" width="900"/> <br/></p> <figcaption style="text-align: center;">Figure 3. Visiting University of Chicago!</figcaption> <hr/> <h2 id="-media-highlights">üì∞ Media Highlights</h2> <p>Our achievement has been featured in several national outlets:</p> <ul> <li><a href="https://www.kalerkantho.com/print-edition/news/2025/06/29/1538935">The Business Standard: UIU MARINER ranks 5th globally, tops Asia in underwater robotics</a></li> <li><a href="https://www.ittefaq.com.bd/738149/">Ittefaq Digital Feature on UIU MARINER</a></li> <li>We were also fortunate to share our story in an live interview at Jamuna TV. Here is the link <a href="https://www.youtube.com/watch?v=c3ZiKPxNolo">Interview at Jamuna TV</a></li> </ul> <p>These stories amplify the message: <em>Bangladesh is ready to lead in global tech innovation</em>.</p> <hr/> <h2 id="-looking-ahead">üöÄ Looking Ahead</h2> <p>This milestone is not the end‚Äîit‚Äôs a beginning. UIU MARINER‚Äôs success opens doors for future Bangladeshi teams to dream bigger, build smarter, and compete globally. As a mentor and researcher, I remain committed to nurturing talent, bridging cultures, and advancing science through education.</p> <p>Let this be a call to all aspiring innovators: the ocean of opportunity is vast, and Bangladesh is ready to dive in.</p> <hr/>]]></content><author><name></name></author><summary type="html"><![CDATA[My Experience as the co-mentor of UIU MARINER and participating in MATEROV World Championship-2025 at USA]]></summary></entry><entry><title type="html">Paper on snoRNA-disease association prediction published in Computers in Biology and Medicine!</title><link href="https://fahimhafiz.github.io/blog/2025/GBDTSVM/" rel="alternate" type="text/html" title="Paper on snoRNA-disease association prediction published in Computers in Biology and Medicine!"/><published>2025-04-24T00:12:13+00:00</published><updated>2025-04-24T00:12:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/GBDTSVM</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/GBDTSVM/"><![CDATA[<h2 id="gbdtsvm-combined-support-vector-machine-and-gradient-boosting-decision-tree-framework-for-efficient-snorna-disease-association-prediction">GBDTSVM: Combined Support Vector Machine and Gradient Boosting Decision Tree Framework for efficient snoRNA-disease association prediction</h2> <p>Excited to share our latest research published in Computers in Biology and Medicine (Q1)!</p> <p>Our paper introduces GBDTSVM, a novel machine learning framework that efficiently predicts snoRNA-disease associations by integrating Gradient Boosting Decision Trees (GBDT) and Support Vector Machines (SVM). With superior performance on multiple datasets, this model offers a powerful tool for advancing snoRNA-related disease research.</p> <p>Check out the full paper and source code here: Paper Link: <a href="https://doi.org/10.1016/j.compbiomed.2025.110219">https://doi.org/10.1016/j.compbiomed.2025.110219</a></p> <p>Source Code:</p> <p><a href="https://github.com/mariamuna04/gbdtsvm">https://github.com/mariamuna04/gbdtsvm</a></p> <p>Congrats and grateful to my authors Ummay Maria Muna, and our supervisor, Riasat Azim!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paper on snoRNA-disease association prediction published in Computers in Biology and Medicine!]]></summary></entry><entry><title type="html">Paper on education design published in Computer Applications in Engineering Education!</title><link href="https://fahimhafiz.github.io/blog/2025/micropaper/" rel="alternate" type="text/html" title="Paper on education design published in Computer Applications in Engineering Education!"/><published>2025-02-20T00:12:13+00:00</published><updated>2025-02-20T00:12:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/micropaper</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/micropaper/"><![CDATA[<h2 id="paper-titled-design-of-a-microprocessors-and-microcontrollers-laboratory-course-addressing-complex-engineering-problems-and-activities-published-in-computer-applications-in-engineering-education-focused-on-desigining-novel-curriculum-and-education-environment">Paper titled ‚ÄúDesign of a Microprocessors and Microcontrollers Laboratory Course Addressing Complex Engineering Problems and Activities‚Äù published in Computer Applications in Engineering Education focused on Desigining Novel Curriculum and Education environment</h2> <p>We are thrilled to announce that our first paper in the field of Education, titled ‚ÄúDesign of a Microprocessors and Microcontrollers Laboratory Course Addressing Complex Engineering Problems and Activities‚Äù, has been accepted for publication in the prestigious journal ‚ÄúComputer Applications in Engineering Education‚Äù by Wiley. This journal is ranked Q1 in both Engineering and Education categories, with an impact factor of 2.0.</p> <p>In this work, we proposed an innovative Laboratory course featuring open-ended labs designed to enable students to solve complex engineering problems and experience complex engineering activities. As we celebrate this milestone, it‚Äôs also a reminder that the journey of improvement never stops‚Äîit‚Äôs time to revisit and enhance the course curriculum once again, technology has evolved that fast! Here‚Äôs to continuous learning, innovation, and pushing the boundaries of engineering and HCI to enhance education curriculum!</p> <p>Check out the preprint and full paper here:</p> <p>Preprint Link: <a href="https://arxiv.org/abs/2503.05741">https://arxiv.org/abs/2503.05741</a></p> <p>Paper Link: <a href="https://doi.org/10.1002/cae.70006">https://doi.org/10.1002/cae.70006</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paper on education design published in Computer Applications in Engineering Education!]]></summary></entry><entry><title type="html">Received crests for my lead role in the CSE Fest 2025 from Vice Chancellor, United International University(UIU)!</title><link href="https://fahimhafiz.github.io/blog/2025/CSE_Fest_25_crest/" rel="alternate" type="text/html" title="Received crests for my lead role in the CSE Fest 2025 from Vice Chancellor, United International University(UIU)!"/><published>2025-02-18T00:32:13+00:00</published><updated>2025-02-18T00:32:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2025/CSE_Fest_25_crest</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2025/CSE_Fest_25_crest/"><![CDATA[<h2 id="uiu-cse-fest-2025-a-grand-celebration-of-technology-and-innovation">UIU CSE Fest 2025: A Grand Celebration of Technology and Innovation</h2> <p>The Computer Science and Engineering (CSE) department of United International University (UIU) recently organized a spectacular technology festival, the UIU CSE Fest 2025. This two-day event saw enthusiastic participation from students across the country, showcasing their technological skills and innovative ideas. Nearly fifteen hundred students took part in various competitions, making the event truly impressive.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/Fest25-collage1.jpg?raw=true" alt="Some moments from the UIU CSE Fest." width="900"/> <br/></p> <figcaption style="text-align: center;">Some moments from the UIU CSE Fest.</figcaption> <h3 id="my-role-treasurer-and-robotics-segment-coordinator">My Role: Treasurer and Robotics Segment Coordinator</h3> <p>I played two significant roles in this large-scale event ‚Äì Treasurer and Robotics Segment Coordinator. As Treasurer, my responsibilities included managing the budgets for different segments, food arrangements, prize money, and concert organization. Simultaneously, as the Robotics Segment Coordinator, I played a key role in planning and conducting the robot-related competitions.</p> <h3 id="what-i-learned">What I Learned</h3> <p>Organizing such a large event taught me a great deal. My skills in time management, teamwork, financial planning, and handling unexpected situations were significantly enhanced. Furthermore, I had the opportunity to interact with students from all over the country, which enriched my knowledge and experience.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/Fest25-Crest.jpg?raw=true" alt="Receiving the crest from the Vice Chancellor of UIU and guests at the closing ceremony." width="900"/> <br/></p> <figcaption style="text-align: center;">Receiving the crest from the Vice Chancellor of UIU and guests at the closing ceremony.</figcaption> <h3 id="recognition">Recognition</h3> <p>As recognition for my work, I received crests from the VC and guests at the closing ceremony. This recognition is a source of immense pride for me and inspires me to work even harder in the future.</p> <h3 id="cse-fest-2025-a-glimpse">CSE Fest 2025: A Glimpse</h3> <p>The fest featured exciting competitions like Line Following Robot, Robo Soccer, Blockchain Olympiad, Programming Contest, Project Show, and ICT Olympiad. There were also various outdoor games, badminton, and table tennis competitions.</p> <h3 id="some-notable-moments">Some Notable Moments</h3> <ul> <li>The International University of Scholars‚Äô Team RoboMore Dynamic Sparks emerged as the champion in the Line Following Robot competition.</li> <li>Two UIU teams, Blue Beetle and C101, secured the champion and first runner-up positions respectively in Robo Soccer.</li> <li>The Blockchain Olympiad saw Yet Another One from Dhaka University win the gold medal.</li> <li>DU Primordials from Dhaka University were crowned champions in the UIU Inter-University Programming Contest.</li> </ul> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/Fest25-collage2.jpg?raw=true" alt="A glimpse of other exciting moments from the UIU CSE Fest." width="900"/> <br/></p> <figcaption style="text-align: center;">A glimpse of other exciting moments from the UIU CSE Fest.</figcaption> <p>The UIU CSE Fest 2025 was a truly successful event, pushing the boundaries of students‚Äô technological knowledge and innovative thinking.</p> <p>Learn more about the UIU CSE Fest:</p> <ul> <li><a href="https://csefest.uiu.ac.bd/">CSE Fest Website</a></li> <li><a href="https://www.facebook.com/profile.php?id=61569420809397">CSE Fest Facebook Page</a></li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Received crests for my lead role in the CSE Fest 2025 from Vice Chancellor, United International University(UIU)!]]></summary></entry><entry><title type="html">Received crests for my organizer role in CSE Project Show from Head of the Department, CSE, UIU!</title><link href="https://fahimhafiz.github.io/blog/2024/CSE_project_show242_crest/" rel="alternate" type="text/html" title="Received crests for my organizer role in CSE Project Show from Head of the Department, CSE, UIU!"/><published>2024-12-29T00:32:13+00:00</published><updated>2024-12-29T00:32:13+00:00</updated><id>https://fahimhafiz.github.io/blog/2024/CSE_project_show242_crest</id><content type="html" xml:base="https://fahimhafiz.github.io/blog/2024/CSE_project_show242_crest/"><![CDATA[<h2 id="uiu-cse-project-show">UIU CSE Project Show</h2> <p>I am thrilled to share that I recently received a crest as one of the main organizers of the <a href="https://www.facebook.com/uiucseps/">‚ÄúCSE Project show‚Äù</a> from the <a href="https://cse.uiu.ac.bd/faculty/mnh/">‚ÄúProf. Dr. Mohammad Nurul Huda‚Äù</a>, Head, Dept. of CSE, UIU and <a href="https://cse.uiu.ac.bd/faculty/muzahid/">‚ÄúProf. Dr. A.K.M. Muzahidul Islam‚Äù</a>, Dept. of CSE, UIU. This recognition is a testament to the hard work and dedication put into making the event a success.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/cseps24_5.jpeg?raw=true" alt="Receiving crest as the organizer from the Head of the Department, CSE, UIU" width="900"/> <br/></p> <figcaption style="text-align: center;">Receiving crest as the organizer from the Head of the Department, CSE, UIU</figcaption> <p>Additionally, the UIU Robotics Club, which played a significant role in the project show, also received crests. Their collaboration and support were crucial in organizing and executing the event successfully. Thanks to UIU Robotics Club President, Mr. Ahmed Junaid Tanim, Ms. Faria Rakib Borsha (GS, UIU Robotics Club), Mr. Rashique Chowdhury (Treasurer, UIU Robotics Club) and others for their significant role. As the moderator of UIU Robotics club, I am proud to have them by our side.</p> <p><img src="https://github.com/FahimHafiz/FahimHafiz.github.io/blob/main/assets/img/cseps24_6.jpeg?raw=true" alt="UIU Robotics Club receiving crest as one of the main partners in the prestigious event" width="900"/> <br/></p> <figcaption style="text-align: center;">UIU Robotics Club receiving crest as one of the main partners in the prestigious event</figcaption> <p>The recognition we received is not just a personal achievement but a reflection of the collective effort of the entire team. Thank you to everyone who contributed to the success of the UIU Summer Project Show 2024!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Received crests for my organizer role in CSE Project Show from Head of the Department, CSE, UIU!]]></summary></entry><entry><title type="html">Excited to work as one of the coordinator and Treasurer of UIU CSE Fest-2025!</title><link href="https://fahimhafiz.github.io/https:/csefest.uiu.ac.bd/gratitude" rel="alternate" type="text/html" title="Excited to work as one of the coordinator and Treasurer of UIU CSE Fest-2025!"/><published>2024-12-02T00:32:13+00:00</published><updated>2024-12-02T00:32:13+00:00</updated><id>https://fahimhafiz.github.io/https:/csefest.uiu.ac.bd/csefest_uiu_25</id><content type="html" xml:base="https://fahimhafiz.github.io/https:/csefest.uiu.ac.bd/gratitude"><![CDATA[<h2 id="about-uiu-cse-fest-2025">About UIU CSE Fest 2025</h2> <p>UIU CSE Fest 2025 is a premier event designed to celebrate innovation, collaboration, and learning within the computer science and engineering community. This fest aims to create a vibrant platform where students, industry professionals, and tech enthusiasts come together to explore cutting-edge advancements in Programming, Software Development, and Robotics.</p> <p>The fest features a variety of engaging events, including the UIU IUPC 2025, Blockchain Olympiad, Project Show, ICT Olympiad, and exciting robotics competitions like the Soccer Bot Competition and Line Follower Robot Competition. Each event is structured to encourage participation, foster creativity, and showcase the talents of aspiring engineers.</p> <p>Through UIU CSE Fest 2025, we aim to empower participants with the knowledge and skills necessary for success in the rapidly evolving tech landscape. We invite you to join us in making this event a transformative experience for all involved, inspiring the next generation of leaders in technology and innovation.</p> <p>Check out our organizing team members: <a href="https://csefest.uiu.ac.bd/gratitude">‚ÄúCentral Organizing Committee of UIU CSE FEST-2025‚Äù</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Excited to work as one of the coordinator and Treasurer of UIU CSE Fest-2025!]]></summary></entry><entry><title type="html">Paper on Rapid Kit Test results prediction from smartphone is arXived!</title><link href="https://fahimhafiz.github.io/https:/arxiv.org/pdf/2411.18007" rel="alternate" type="text/html" title="Paper on Rapid Kit Test results prediction from smartphone is arXived!"/><published>2024-11-27T00:32:13+00:00</published><updated>2024-11-27T00:32:13+00:00</updated><id>https://fahimhafiz.github.io/https:/arxiv.org/pdf/rapid_kit_arxiv</id><content type="html" xml:base="https://fahimhafiz.github.io/https:/arxiv.org/pdf/2411.18007"><![CDATA[<h2 id="ai-driven-smartphone-solution-for-digitizing-rapid-diagnostic-test-kits-and-enhancing-accessibility-for-the-visually-impaired">AI-Driven Smartphone Solution for Digitizing Rapid Diagnostic Test Kits and Enhancing Accessibility for the Visually Impaired</h2> <p>Rapid diagnostic tests are crucial for timely disease detection and management, yet accurate interpretation of test results remains challenging. In this study, we propose a novel approach to enhance the accuracy and reliability of rapid diagnostic test result interpretation by integrating artificial intelligence (AI) algorithms, including convolutional neural networks (CNN), within a smartphone-based application. The app enables users to take pictures of their test kits, which YOLOv8 then processes to precisely crop and extract the membrane region, even if the test kit is not centered in the frame or is positioned at the very edge of the image. This capability offers greater accessibility, allowing even visually impaired individuals to capture test images without needing perfect alignment, thus promoting user independence and inclusivity. The extracted image is analyzed by an additional CNN classifier that determines if the results are positive, negative, or invalid, providing users with the results and a confidence level. Through validation experiments with commonly used rapid test kits across various diagnostic applications, our results demonstrate that the synergistic integration of AI significantly improves sensitivity and specificity in test result interpretation. This improvement can be attributed to the extraction of the membrane zones from the test kit images using the state-of-the-art YOLO algorithm. Additionally, we performed SHapley Additive exPlanations (SHAP) analysis to investigate the factors influencing the model‚Äôs decisions, identifying reasons behind both correct and incorrect classifications. By facilitating the differentiation of genuine test lines from background noise and providing valuable insights into test line intensity and uniformity, our approach offers a robust solution to challenges in rapid test interpretation.</p> <p>Check out the paper: <a href="https://arxiv.org/abs/2411.18007">‚Äúarchived version‚Äù</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Paper on Rapid Kit Test results prediction from smartphone is arXived!]]></summary></entry></feed>