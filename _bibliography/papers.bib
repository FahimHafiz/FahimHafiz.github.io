---
---


@inproceedings{sayeedi2024mosquitofusion,
  title={MosquitoFusion: A Multiclass Dataset for Real-Time Detection of Mosquitoes, Swarms, and Breeding Sites Using Deep Learning},
  abstract={In this paper, we present an integrated approach to real-time mosquito detection using our multiclass dataset (MosquitoFusion) containing 1204 diverse images and leverage cutting-edge technologies, specifically computer vision, to automate the identification of Mosquitoes, Swarms, and Breeding Sites. The pre-trained YOLOv8 model, trained on this dataset, achieved a mean Average Precision (mAP@50) of 57.1%, with precision at 73.4% and recall at 50.5%. The integration of Geographic Information Systems (GIS) further enriches the depth of our analysis, providing valuable insights into spatial patterns. The dataset and code are available at https://github.com/faiyazabdullah/MosquitoFusion.},
  author={Sayeedi, Md Faiyaz Abdullah and Hafiz, Fahim and Rahman, Md Ashiqur},
  booktitle={The Second Tiny Papers Track at ICLR 2024},
  year={2024},
  doi={https://doi.org/10.48550/arXiv.2404.01501},
  selected={true},
  pdf={https://arxiv.org/pdf/2404.01501},
  preview = {mosquito_fusion.png}
}

@article{dastagir2024ai,
  title={AI-Driven Smartphone Solution for Digitizing Rapid Diagnostic Test Kits and Enhancing Accessibility for the Visually Impaired},
  abstract={Rapid diagnostic tests are crucial for timely disease detection and management, yet accurate interpretation of test results remains challenging. In this study, we propose a novel approach to enhance the accuracy and reliability of rapid diagnostic test result interpretation by integrating artificial intelligence (AI) algorithms, including convolutional neural networks (CNN), within a smartphone-based application. The app enables users to take pictures of their test kits, which YOLOv8 then processes to precisely crop and extract the membrane region, even if the test kit is not centered in the frame or is positioned at the very edge of the image. This capability offers greater accessibility, allowing even visually impaired individuals to capture test images without needing perfect alignment, thus promoting user independence and inclusivity. The extracted image is analyzed by an additional CNN classifier that determines if the results are positive, negative, or invalid, providing users with the results and a confidence level. Through validation experiments with commonly used rapid test kits across various diagnostic applications, our results demonstrate that the synergistic integration of AI significantly improves sensitivity and specificity in test result interpretation. This improvement can be attributed to the extraction of the membrane zones from the test kit images using the state-of-the-art YOLO algorithm. Additionally, we performed SHapley Additive exPlanations (SHAP) analysis to investigate the factors influencing the model's decisions, identifying reasons behind both correct and incorrect classifications. By facilitating the differentiation of genuine test lines from background noise and providing valuable insights into test line intensity and uniformity, our approach offers a robust solution to challenges in rapid test interpretation.},
  author={Dastagir, RB and Jami, JT and Chanda, S and Hafiz, F and Rahman, M and Dey, K and Rahman, MM and Qureshi, M and Chowdhury, MM},
  journal={arXiv preprint arXiv:2411.18007},
  year={2024},
  doi={https://doi.org/10.48550/arXiv.2411.18007},
  selected={true},
  pdf={https://arxiv.org/pdf/2411.18007},
  preview = {rapid_kit_arxiv.png}
}

@INPROCEEDINGS{10499623,
  author={Mohammad Emon, Khan and Kibria, Golam and Shakhan, Md. and Jannat, Bushra and Hafiz, Fahim and Azim, Riasat},
  abstract={Breast cancer is a complicated and diverse ailment that requires thorough understanding at the cellular level to provide more accurate diagnoses and customized treatments. This work explores the categorization and division of breast cancer cells using imaging technology, computational algorithms, and histopathology examination. The classification result was derived by building a hybrid model that combined RNN and EfficientNetV2S with an accuracy of 99.99%, the model demonstrated promising improvement over the baseline, even though it acknowledged the influence of sparse data on outcomes. On the other hand, the segmentation result was derived by modifying the pre-trained model “U-Net” with an attention mechanism where the model was also able to achieve a significant accuracy of 99.54%.To achieve an understanding of the many subtleties of breast cancer, this study emphasizes the significance of classifying and segmenting cells at the individual cell level. It is possible to achieve a thorough understanding by using deep learning and machine learning models on image data.},
  booktitle={2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)}, 
  title={ENRNN-AU-Net: A Hybrid Deep Learning Model to Classify and Segment Histopathology Images of Breast Cancer}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Deep learning;Image segmentation;Chemotherapy;Histopathology;Computational modeling;Computer architecture;Breast cancer;Hybrid Model;EjficientNetV2S;RNN;ImageNet;U- Net;Attention},
  doi={10.1109/iCACCESS61735.2024.10499623},
  preview = {ENN-AU-Net.png}
}

@article{islam2024mosquitominer,
  title={MosquitoMiner: A Light Weight Rover for Detecting and Eliminating Mosquito Breeding Sites},
  abstract={In this paper, we present a novel approach to the development and deployment of an autonomous mosquito breeding place detector rover with the object and obstacle detection capabilities to control mosquitoes. Mosquito-borne diseases continue to pose significant health threats globally, with conventional control methods proving slow and inefficient. Amidst rising concerns over the rapid spread of these diseases, there is an urgent need for innovative and efficient strategies to manage mosquito populations and prevent disease transmission. To mitigate the limitations of manual labor and traditional methods, our rover employs autonomous control strategies. Leveraging our own custom dataset, the rover can autonomously navigate along a pre-defined path, identifying and mitigating potential breeding grounds with precision. It then proceeds to eliminate these breeding grounds by spraying a chemical agent, effectively eradicating mosquito habitats. Our project demonstrates the effectiveness that is absent in traditional ways of controlling and safeguarding public health. The code for this project is available on GitHub at - https://github.com/faiyazabdullah/MosquitoMiner},
  author={Islam, Md Adnanul and Sayeedi, Md Faiyaz Abdullah and Deepti, Jannatul Ferdous and Bappy, Shahanur Rahman and Islam, Safrin Sanzida and Hafiz, Fahim},
  journal={arXiv preprint arXiv:2409.08078},
  year={2024},
  doi={https://doi.org/10.48550/arXiv.2409.08078},
  pdf={https://arxiv.org/pdf/2409.08078},
  preview = {mosquito_miner.png}
}